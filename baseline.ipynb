{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongwook95.lee/miniforge3/envs/hvae/lib/python3.8/site-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from data_utils.data_utils import prepare_data, get_dataset, get_test_dataset, sound_dataset_generator, sound_dataset_generator_by_filename\n",
    "from model.baseline import Baseline\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform wav to npy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_result_path = \"./example\"\n",
    "train_data_dir = \"/home/jongwook95.lee/study/cnn_based_audio_classification/dataset/audio_files/train/ok/\"\n",
    "remove_filename_list = []\n",
    "n_mels = 128\n",
    "frames = 5\n",
    "n_fft = 1024\n",
    "hop_length = 256\n",
    "power = 2\n",
    "sr = 16000\n",
    "\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Make Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy Files already exists.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_dir = os.path.join(experiment_result_path, 'train_dataset.npy')\n",
    "\n",
    "if os.path.exists(train_dataset_dir):\n",
    "    print(\"npy Files already exists.\")\n",
    "    train_dataset = np.load(train_dataset_dir)\n",
    "else:\n",
    "    print(\"Convert Audio files to Spectrogram npy files... (Train filesets)\")\n",
    "    train_file_list = prepare_data(train_data_dir, remove_filename_list=remove_filename_list)\n",
    "    train_dataset = get_dataset(train_file_list, n_mels=n_mels, \n",
    "                                frames=frames, n_fft=n_fft, hop_length=hop_length,\n",
    "                                power=power, sr=sr)\n",
    "    np.save(train_dataset_dir, train_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Make Pytorch Dataloader (Train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataset = sound_dataset_generator(train_dataset)\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "model_save_dir = \"./example/best_model/baseline_model.pt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of model parameters: 267928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Baseline(\n",
       "  (fc1): Linear(in_features=640, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc5): Linear(in_features=128, out_features=8, bias=True)\n",
       "  (bn5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc6): Linear(in_features=8, out_features=128, bias=True)\n",
       "  (bn6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc7): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc8): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc9): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc10): Linear(in_features=128, out_features=640, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Baseline(input_dims = n_mels * frames)\n",
    "print(\"number of model parameters:\",sum([np.prod(p.size()) for p in model.parameters()]))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Set up the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=45, gamma=0.1)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongwook95.lee/miniforge3/envs/hvae/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/jongwook95.lee/miniforge3/envs/hvae/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "100%|██████████| 15750/15750 [02:25<00:00, 108.56it/s]\n",
      "  0%|          | 0/15750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 200, train average loss: 95.38664162965804\n",
      "min loss updated 10000000 to 95.38664162965804. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.68it/s]\n",
      "  0%|          | 1/15750 [00:00<33:34,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 200, train average loss: 11.34131198834616\n",
      "min loss updated 95.38664162965804 to 11.34131198834616. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:32<00:00, 103.21it/s]\n",
      "  0%|          | 1/15750 [00:00<30:34,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 200, train average loss: 10.756956933884394\n",
      "min loss updated 11.34131198834616 to 10.756956933884394. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.61it/s]\n",
      "  0%|          | 1/15750 [00:00<30:43,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 200, train average loss: 10.466032933068654\n",
      "min loss updated 10.756956933884394 to 10.466032933068654. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:34<00:00, 102.24it/s]\n",
      "  0%|          | 1/15750 [00:00<30:49,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 200, train average loss: 10.296504048544262\n",
      "min loss updated 10.466032933068654 to 10.296504048544262. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:26<00:00, 107.51it/s]\n",
      "  0%|          | 1/15750 [00:00<30:18,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 / 200, train average loss: 10.181841905139741\n",
      "min loss updated 10.296504048544262 to 10.181841905139741. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:31<00:00, 103.95it/s]\n",
      "  0%|          | 1/15750 [00:00<29:58,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 200, train average loss: 10.095421630617173\n",
      "min loss updated 10.181841905139741 to 10.095421630617173. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:24<00:00, 109.31it/s]\n",
      "  0%|          | 1/15750 [00:00<29:58,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 200, train average loss: 10.027760031321693\n",
      "min loss updated 10.095421630617173 to 10.027760031321693. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:30<00:00, 104.69it/s]\n",
      "  0%|          | 1/15750 [00:00<29:12,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 200, train average loss: 9.973560148874919\n",
      "min loss updated 10.027760031321693 to 9.973560148874919. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:23<00:00, 109.72it/s]\n",
      "  0%|          | 1/15750 [00:00<30:52,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / 200, train average loss: 9.929384046645392\n",
      "min loss updated 9.973560148874919 to 9.929384046645392. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:23<00:00, 110.07it/s]\n",
      "  0%|          | 1/15750 [00:00<26:43,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 / 200, train average loss: 9.889921200222439\n",
      "min loss updated 9.929384046645392 to 9.889921200222439. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 108.10it/s]\n",
      "  0%|          | 1/15750 [00:00<30:17,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 / 200, train average loss: 9.855734832279266\n",
      "min loss updated 9.889921200222439 to 9.855734832279266. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:23<00:00, 109.94it/s]\n",
      "  0%|          | 1/15750 [00:00<26:23,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 / 200, train average loss: 9.8293049378168\n",
      "min loss updated 9.855734832279266 to 9.8293049378168. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:33<00:00, 102.51it/s]\n",
      "  0%|          | 1/15750 [00:00<30:11,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 / 200, train average loss: 9.80571489043463\n",
      "min loss updated 9.8293049378168 to 9.80571489043463. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:28<00:00, 105.88it/s]\n",
      "  0%|          | 1/15750 [00:00<30:56,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 / 200, train average loss: 9.784171602461074\n",
      "min loss updated 9.80571489043463 to 9.784171602461074. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 108.05it/s]\n",
      "  0%|          | 1/15750 [00:00<34:36,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 / 200, train average loss: 9.763471107967316\n",
      "min loss updated 9.784171602461074 to 9.763471107967316. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:31<00:00, 103.68it/s]\n",
      "  0%|          | 1/15750 [00:00<30:58,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 / 200, train average loss: 9.745783100975885\n",
      "min loss updated 9.763471107967316 to 9.745783100975885. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:31<00:00, 103.67it/s]\n",
      "  0%|          | 1/15750 [00:00<30:40,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 / 200, train average loss: 9.731600159175812\n",
      "min loss updated 9.745783100975885 to 9.731600159175812. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:30<00:00, 104.48it/s]\n",
      "  0%|          | 1/15750 [00:00<31:03,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 / 200, train average loss: 9.71777151749626\n",
      "min loss updated 9.731600159175812 to 9.71777151749626. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 107.97it/s]\n",
      "  0%|          | 1/15750 [00:00<30:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 / 200, train average loss: 9.704654454004197\n",
      "min loss updated 9.71777151749626 to 9.704654454004197. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:24<00:00, 108.75it/s]\n",
      "  0%|          | 1/15750 [00:00<35:23,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 / 200, train average loss: 9.69279466047741\n",
      "min loss updated 9.704654454004197 to 9.69279466047741. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:27<00:00, 106.70it/s]\n",
      "  0%|          | 2/15750 [00:00<14:02, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 / 200, train average loss: 9.682135403890458\n",
      "min loss updated 9.69279466047741 to 9.682135403890458. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.25it/s]\n",
      "  0%|          | 1/15750 [00:00<32:01,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 / 200, train average loss: 9.672945621672131\n",
      "min loss updated 9.682135403890458 to 9.672945621672131. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:26<00:00, 107.21it/s]\n",
      "  0%|          | 1/15750 [00:00<30:06,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 / 200, train average loss: 9.661869683099171\n",
      "min loss updated 9.672945621672131 to 9.661869683099171. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:18<00:00, 113.60it/s]\n",
      "  0%|          | 1/15750 [00:00<27:34,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 / 200, train average loss: 9.653764102693588\n",
      "min loss updated 9.661869683099171 to 9.653764102693588. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:22<00:00, 110.17it/s]\n",
      "  0%|          | 1/15750 [00:00<29:28,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 / 200, train average loss: 9.645778335813493\n",
      "min loss updated 9.653764102693588 to 9.645778335813493. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:17<00:00, 114.92it/s]\n",
      "  0%|          | 1/15750 [00:00<26:53,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 / 200, train average loss: 9.639003268347846\n",
      "min loss updated 9.645778335813493 to 9.639003268347846. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:20<00:00, 112.19it/s]\n",
      "  0%|          | 1/15750 [00:00<28:56,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 / 200, train average loss: 9.63198957915533\n",
      "min loss updated 9.639003268347846 to 9.63198957915533. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:17<00:00, 114.31it/s]\n",
      "  0%|          | 1/15750 [00:00<29:19,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 / 200, train average loss: 9.624984879084996\n",
      "min loss updated 9.63198957915533 to 9.624984879084996. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:18<00:00, 113.75it/s]\n",
      "  0%|          | 1/15750 [00:00<29:25,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 / 200, train average loss: 9.619103030310736\n",
      "min loss updated 9.624984879084996 to 9.619103030310736. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:27<00:00, 107.04it/s]\n",
      "  0%|          | 1/15750 [00:00<27:27,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 / 200, train average loss: 9.614145173935663\n",
      "min loss updated 9.619103030310736 to 9.614145173935663. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:17<00:00, 114.28it/s]\n",
      "  0%|          | 1/15750 [00:00<34:47,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 / 200, train average loss: 9.606167260730077\n",
      "min loss updated 9.614145173935663 to 9.606167260730077. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.53it/s]\n",
      "  0%|          | 1/15750 [00:00<30:08,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 / 200, train average loss: 9.600738413129534\n",
      "min loss updated 9.606167260730077 to 9.600738413129534. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.64it/s]\n",
      "  0%|          | 1/15750 [00:00<28:47,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 / 200, train average loss: 9.596500381954133\n",
      "min loss updated 9.600738413129534 to 9.596500381954133. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:24<00:00, 109.35it/s]\n",
      "  0%|          | 1/15750 [00:00<32:22,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 / 200, train average loss: 9.591441515665206\n",
      "min loss updated 9.596500381954133 to 9.591441515665206. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:31<00:00, 103.94it/s]\n",
      "  0%|          | 1/15750 [00:00<29:57,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 / 200, train average loss: 9.586397515130422\n",
      "min loss updated 9.591441515665206 to 9.586397515130422. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:30<00:00, 104.64it/s]\n",
      "  0%|          | 1/15750 [00:00<29:40,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 / 200, train average loss: 9.581037144191681\n",
      "min loss updated 9.586397515130422 to 9.581037144191681. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 108.46it/s]\n",
      "  0%|          | 1/15750 [00:00<33:03,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 / 200, train average loss: 9.576325738937136\n",
      "min loss updated 9.581037144191681 to 9.576325738937136. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 108.54it/s]\n",
      "  0%|          | 1/15750 [00:00<30:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 / 200, train average loss: 9.571785474746946\n",
      "min loss updated 9.576325738937136 to 9.571785474746946. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:27<00:00, 107.01it/s]\n",
      "  0%|          | 1/15750 [00:00<29:38,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 / 200, train average loss: 9.568527389465816\n",
      "min loss updated 9.571785474746946 to 9.568527389465816. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:33<00:00, 102.82it/s]\n",
      "  0%|          | 1/15750 [00:00<29:06,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 / 200, train average loss: 9.56362930667211\n",
      "min loss updated 9.568527389465816 to 9.56362930667211. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:28<00:00, 105.71it/s]\n",
      "  0%|          | 1/15750 [00:00<30:38,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 / 200, train average loss: 9.559440006316654\n",
      "min loss updated 9.56362930667211 to 9.559440006316654. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.41it/s]\n",
      "  0%|          | 1/15750 [00:00<29:51,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 / 200, train average loss: 9.558402826036726\n",
      "min loss updated 9.559440006316654 to 9.558402826036726. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:31<00:00, 103.97it/s]\n",
      "  0%|          | 1/15750 [00:00<29:51,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 / 200, train average loss: 9.552754451872811\n",
      "min loss updated 9.558402826036726 to 9.552754451872811. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:28<00:00, 105.81it/s]\n",
      "  0%|          | 1/15750 [00:00<29:20,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 / 200, train average loss: 9.549675325060647\n",
      "min loss updated 9.552754451872811 to 9.549675325060647. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:30<00:00, 104.92it/s]\n",
      "  0%|          | 1/15750 [00:00<28:53,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 / 200, train average loss: 9.501228020622616\n",
      "min loss updated 9.549675325060647 to 9.501228020622616. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:27<00:00, 106.95it/s]\n",
      "  0%|          | 2/15750 [00:00<13:45, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 / 200, train average loss: 9.497888240269253\n",
      "min loss updated 9.501228020622616 to 9.497888240269253. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:22<00:00, 110.15it/s]\n",
      "  0%|          | 1/15750 [00:00<29:45,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 / 200, train average loss: 9.496029986850798\n",
      "min loss updated 9.497888240269253 to 9.496029986850798. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:26<00:00, 107.46it/s]\n",
      "  0%|          | 1/15750 [00:00<30:01,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 / 200, train average loss: 9.495564238593692\n",
      "min loss updated 9.496029986850798 to 9.495564238593692. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:31<00:00, 104.13it/s]\n",
      "  0%|          | 1/15750 [00:00<33:10,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 / 200, train average loss: 9.494662232535227\n",
      "min loss updated 9.495564238593692 to 9.494662232535227. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.19it/s]\n",
      "  0%|          | 1/15750 [00:00<30:03,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 / 200, train average loss: 9.49367098308745\n",
      "min loss updated 9.494662232535227 to 9.49367098308745. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:23<00:00, 110.11it/s]\n",
      "  0%|          | 1/15750 [00:00<30:18,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 / 200, train average loss: 9.491929723891001\n",
      "min loss updated 9.49367098308745 to 9.491929723891001. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:29<00:00, 105.08it/s]\n",
      "  0%|          | 1/15750 [00:00<29:16,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 / 200, train average loss: 9.49125416770814\n",
      "min loss updated 9.491929723891001 to 9.49125416770814. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:30<00:00, 104.38it/s]\n",
      "  0%|          | 1/15750 [00:00<27:38,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 / 200, train average loss: 9.490523000565787\n",
      "min loss updated 9.49125416770814 to 9.490523000565787. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:30<00:00, 104.68it/s]\n",
      "  0%|          | 1/15750 [00:00<30:09,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 / 200, train average loss: 9.489445043957422\n",
      "min loss updated 9.490523000565787 to 9.489445043957422. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 108.26it/s]\n",
      "  0%|          | 1/15750 [00:00<29:41,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 / 200, train average loss: 9.489342310284812\n",
      "min loss updated 9.489445043957422 to 9.489342310284812. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:34<00:00, 101.77it/s]\n",
      "  0%|          | 1/15750 [00:00<29:56,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 / 200, train average loss: 9.488342087881906\n",
      "min loss updated 9.489342310284812 to 9.488342087881906. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15750/15750 [02:25<00:00, 108.16it/s]\n",
      "  0%|          | 1/15750 [00:00<26:54,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 / 200, train average loss: 9.487691348000178\n",
      "min loss updated 9.488342087881906 to 9.487691348000178. New model saved!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 5056/15750 [02:50<05:01, 35.45it/s] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### 5. Model Train\n",
    "min_loss = 10000000\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    scheduler.step(epoch)\n",
    "    loop = tqdm(train_loader, total = len(train_loader), leave = True)\n",
    "    lossfs = []\n",
    "    for feature in loop:\n",
    "        feature = feature.float()\n",
    "        feature = feature.to(device)\n",
    "        out = model(feature)\n",
    "        \n",
    "        loss = loss_fn(out, feature)\n",
    "        lossf = loss.data.item()\n",
    "        lossfs.append(lossf)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    print(\"Epoch: {} / {}, train average loss: {}\".format(epoch, epochs, np.mean(lossfs)))\n",
    "    if min_loss > np.mean(lossfs):\n",
    "        print(\"min loss updated {} to {}. New model saved!!\".format(min_loss, np.mean(lossfs)))\n",
    "        min_loss = np.mean(lossfs)\n",
    "        torch.save(model.state_dict(), model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Make Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = \"/home/jongwook95.lee/study/cnn_based_audio_classification/dataset/audio_files/test/ng/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 20.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset_dir = os.path.join(experiment_result_path, 'test')\n",
    "\n",
    "if os.path.exists(test_dataset_dir):\n",
    "    print(\"npy files is already extracted.\")\n",
    "    test_npy_list = prepare_data(test_dataset_dir, remove_filename_list=remove_filename_list)\n",
    "else:\n",
    "    os.makedirs(test_dataset_dir, exist_ok=True)\n",
    "    test_file_list = prepare_data(test_data_dir, remove_filename_list=remove_filename_list)\n",
    "    get_test_dataset(test_file_list, test_dataset_dir, n_mels=n_mels, \n",
    "                                frames=frames, n_fft=n_fft, hop_length=hop_length,\n",
    "                                power=power, sr=sr)\n",
    "    test_npy_list = prepare_data(test_dataset_dir, remove_filename_list=remove_filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Make Pytorch Dataloader (Test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_dataset = sound_dataset_generator_by_filename(test_npy_list)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_dir = \"./example/best_model/baseline_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline(\n",
       "  (fc1): Linear(in_features=640, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc5): Linear(in_features=128, out_features=8, bias=True)\n",
       "  (bn5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc6): Linear(in_features=8, out_features=128, bias=True)\n",
       "  (bn6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc7): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc8): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc9): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc10): Linear(in_features=128, out_features=640, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Baseline(input_dims = n_mels * frames)\n",
    "model.load_state_dict(torch.load(model_load_dir))\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 302.92it/s]\n"
     ]
    }
   ],
   "source": [
    "anomaly_score_list = []\n",
    "\n",
    "loop = tqdm(test_loader, total = len(test_loader), leave = True)\n",
    "with torch.no_grad():\n",
    "    for feature in loop:\n",
    "        feature = feature.float()\n",
    "        feature = feature[0]\n",
    "        feature = feature.to(device)\n",
    "        out = model(feature)\n",
    "        loss = loss_fn(out, feature)\n",
    "\n",
    "        loss_average = torch.mean(loss).cpu().detach()\n",
    "        loss_median = torch.median(loss).cpu().detach()\n",
    "        loss_list = [loss_average, loss_median]\n",
    "        loss = np.array([loss_list])\n",
    "        anomaly_score_list = anomaly_score_list + [loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Save a Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_filename = 'baseline_test_ng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_score_list = np.vstack(anomaly_score_list)\n",
    "result1 = pd.DataFrame(anomaly_score_list)\n",
    "file_name_list = [os.path.basename(file) for file in test_npy_list]\n",
    "result = pd.DataFrame({'File': file_name_list})\n",
    "result = pd.concat([result, result1], axis = 1)\n",
    "result.columns = ['File', 'Mean', 'Median']\n",
    "result_path = os.path.join(experiment_result_path, 'test_prediction')\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "result.to_csv(result_path + '/' + test_prediction_filename + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d4df077a2d77b6901497b852d021a6adbc6c05eef8db3dd97e21992da26b7f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hvae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
